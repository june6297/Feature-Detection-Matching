{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"10BAbHJVSMx8eGT8vCWYk0mJNJQWmjYaz","authorship_tag":"ABX9TyNHGHHTHVR/cjx0UtPkf3yK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ln3cFeJ3kK_k","executionInfo":{"status":"ok","timestamp":1725462733621,"user_tz":-540,"elapsed":74751,"user":{"displayName":"박세훈","userId":"03887704865760519772"}},"outputId":"7ea09ff9-2f9e-4ec0-bda6-5be73ef36265"},"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluating SIFT: 100%|██████████| 59/59 [00:20<00:00,  2.87it/s]\n","Evaluating ORB: 100%|██████████| 59/59 [00:02<00:00, 27.49it/s]\n","Evaluating AKAZE: 100%|██████████| 59/59 [00:02<00:00, 22.74it/s]\n","Evaluating BRISK: 100%|██████████| 59/59 [00:49<00:00,  1.20it/s]"]},{"output_type":"stream","name":"stdout","text":["Extended Results:\n","SIFT: Quality = 0.0000, Repeatability = 0.0000\n","ORB: Quality = 0.0000, Repeatability = 0.0011\n","AKAZE: Quality = 0.0000, Repeatability = 0.0000\n","BRISK: Quality = 0.0000, Repeatability = 0.0000\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["import cv2\n","import numpy as np\n","import os\n","import time\n","from tqdm import tqdm\n","\n","def detect_features(image, algorithm):\n","    if algorithm == 'SIFT':\n","        detector = cv2.SIFT_create()\n","    elif algorithm == 'ORB':\n","        detector = cv2.ORB_create()\n","    elif algorithm == 'AKAZE':\n","        detector = cv2.AKAZE_create()\n","    elif algorithm == 'BRISK':\n","        detector = cv2.BRISK_create()\n","    else:\n","        raise ValueError(f\"Unsupported algorithm: {algorithm}\")\n","\n","    start_time = time.time()\n","    keypoints, descriptors = detector.detectAndCompute(image, None)\n","    end_time = time.time()\n","\n","    return keypoints, descriptors, end_time - start_time\n","\n","def evaluate_feature_quality(image1, image2, keypoints1, keypoints2, descriptors1, descriptors2):\n","    # 특징점 매칭\n","    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n","    matches = bf.match(descriptors1, descriptors2)\n","    matches = sorted(matches, key=lambda x: x.distance)\n","\n","    # 매칭 품질 평가\n","    good_matches = [m for m in matches if m.distance < 0.7 * matches[0].distance]\n","    return len(good_matches) / len(keypoints1) if keypoints1 else 0\n","\n","def evaluate_repeatability(image1, image2, keypoints1, keypoints2):\n","    # 이미지 크기 가져오기\n","    h, w = image1.shape[:2]\n","\n","    # 키포인트를 픽셀 좌표로 변환\n","    pts1 = np.float32([kp.pt for kp in keypoints1]).reshape(-1, 1, 2)\n","    pts2 = np.float32([kp.pt for kp in keypoints2]).reshape(-1, 1, 2)\n","\n","    # 최소 4개의 매칭점이 필요합니다\n","    if len(pts1) < 4 or len(pts2) < 4:\n","        return 0  # 충분한 점이 없으면 0을 반환\n","\n","    try:\n","        # 호모그래피 계산\n","        H, mask = cv2.findHomography(pts1, pts2, cv2.RANSAC, 5.0)\n","\n","        if H is None:\n","            return 0  # 호모그래피를 찾을 수 없으면 0을 반환\n","\n","        # 반복성 계산\n","        good_pts1 = []\n","        good_pts2 = []\n","        for (x1, y1), (x2, y2), m in zip(pts1.reshape(-1, 2), pts2.reshape(-1, 2), mask):\n","            if m:\n","                pt1 = np.array([x1, y1, 1]).reshape(3, 1)\n","                pt2_pred = H.dot(pt1).reshape(3)\n","                pt2_pred = pt2_pred[:2] / pt2_pred[2]\n","                if np.linalg.norm(pt2_pred - [x2, y2]) < 3:  # 3픽셀 임계값\n","                    good_pts1.append((x1, y1))\n","                    good_pts2.append((x2, y2))\n","\n","        return len(good_pts1) / len(pts1) if len(pts1) > 0 else 0\n","\n","    except cv2.error:\n","        return 0  # OpenCV 오류 발생 시 0을 반환\n","def evaluate_algorithm_extended(algorithm, image_folder):\n","    image_files = sorted(os.listdir(image_folder))\n","    quality_scores = []\n","    repeatability_scores = []\n","\n","    for i in tqdm(range(len(image_files) - 1), desc=f\"Evaluating {algorithm}\"):\n","        image1_path = os.path.join(image_folder, image_files[i])\n","        image2_path = os.path.join(image_folder, image_files[i+1])\n","\n","        image1 = cv2.imread(image1_path, cv2.IMREAD_GRAYSCALE)\n","        image2 = cv2.imread(image2_path, cv2.IMREAD_GRAYSCALE)\n","\n","        if image1 is None or image2 is None:\n","            continue\n","\n","        # 특징점 검출 및 디스크립터 계산\n","        keypoints1, descriptors1, _ = detect_features(image1, algorithm)\n","        keypoints2, descriptors2, _ = detect_features(image2, algorithm)\n","\n","        # 품질 평가\n","        quality_score = evaluate_feature_quality(image1, image2, keypoints1, keypoints2, descriptors1, descriptors2)\n","        quality_scores.append(quality_score)\n","\n","        # 반복성 평가\n","        repeatability_score = evaluate_repeatability(image1, image2, keypoints1, keypoints2)\n","        repeatability_scores.append(repeatability_score)\n","\n","    return np.mean(quality_scores), np.mean(repeatability_scores)\n","\n","# 메인 실행 부분\n","image_folder = \"/content/drive/MyDrive/KeyPoint/dataset_split/test/damaged\"\n","algorithms = ['SIFT', 'ORB', 'AKAZE', 'BRISK']\n","\n","extended_results = {}\n","\n","for algorithm in algorithms:\n","    quality, repeatability = evaluate_algorithm_extended(algorithm, image_folder)\n","    extended_results[algorithm] = {'quality': quality, 'repeatability': repeatability}\n","\n","print(\"Extended Results:\")\n","for alg, res in extended_results.items():\n","    print(f\"{alg}: Quality = {res['quality']:.4f}, Repeatability = {res['repeatability']:.4f}\")"]},{"cell_type":"code","source":[],"metadata":{"id":"1kI8sguxkWQV"},"execution_count":null,"outputs":[]}]}